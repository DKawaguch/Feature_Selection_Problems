{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iniciar Sessão Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x0000025AFFF379E0>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set up environment variables\n",
    "os.environ['JAVA_HOME'] = r'C:\\Program Files\\Java\\jdk-21'\n",
    "os.environ['SPARK_HOME'] = r'C:\\Users\\kawda\\Downloads\\spark-3.5.4-bin-hadoop3\\spark-3.5.4-bin-hadoop3'\n",
    "\n",
    "# Initialize a Spark session\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "\t.master(\"local[*]\") \\\n",
    "\t.config(\"spark.executor.memory\", \"8g\") \\\n",
    "\t.config(\"spark.driver.memory\", \"8g\") \\\n",
    "\t.getOrCreate()\n",
    "\n",
    "# Verify the Spark session\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, NumericType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, count, when, isnan, lit, approx_count_distinct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir os dados disponíveis sobre o titanic\n",
    "df_test = spark.read.csv(\"test.csv\", header=True, inferSchema=True)\n",
    "df_test.createOrReplaceTempView(\"df_test\")\n",
    "\n",
    "df_train = spark.read.csv(\"train.csv\", header=True, inferSchema=True)\n",
    "df_train.createOrReplaceTempView(\"df_train\")\n",
    "\n",
    "df_survived = spark.read.csv(\"gender_submission.csv\", header=True, inferSchema=True)\n",
    "df_survived.createOrReplaceTempView(\"df_survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verificar os dados\n",
    "lista_spec = ['PassengerId', 'Survived']\n",
    "abt_00 = df_train.drop(*lista_spec)\n",
    "\n",
    "abt_00.show(5)\n",
    "abt_00.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento inicial padrão (Alta porcentagem de nulos, Variáveis constantes, Missings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- coluna: string (nullable = true)\n",
      " |-- tipo: string (nullable = true)\n",
      " |-- qt_nulos: long (nullable = true)\n",
      " |-- percent_nulos: double (nullable = true)\n",
      " |-- cardinalidade: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_metadata(df):\n",
    "    metadata_list = []\n",
    "    \n",
    "    for coluna in df.schema:\n",
    "        col_name = coluna.name\n",
    "        data_type = str(coluna.dataType)\n",
    "\n",
    "        total_count = df.count()\n",
    "        null_count = df.filter(F.col(col_name).isNull()).count()\n",
    "        non_null_percentage = (total_count - null_count) / total_count if total_count > 0 else 0\n",
    "        cardinality = df.select(col_name).agg(F.countDistinct(F.col(col_name))).collect()[0][0]\n",
    "\n",
    "        metadata_list.append((col_name, data_type, null_count, 1 - non_null_percentage, cardinality))\n",
    "    \n",
    "    metadata = spark.createDataFrame(metadata_list, [\"coluna\", \"tipo\", \"qt_nulos\", \"percent_nulos\", \"cardinalidade\"])\n",
    "    return metadata\n",
    "\n",
    "metadados = get_metadata(abt_00)\n",
    "metadados.createOrReplaceTempView(\"metadados\")\n",
    "metadados.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+----+-----+-----+----------------+-------+------------+--------+\n",
      "|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|       Cabin|Embarked|\n",
      "+------+--------------------+------+----+-----+-----+----------------+-------+------------+--------+\n",
      "|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25|Desconhecido|       S|\n",
      "|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|         C85|       C|\n",
      "|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925|Desconhecido|       S|\n",
      "|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1|        C123|       S|\n",
      "|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05|Desconhecido|       S|\n",
      "+------+--------------------+------+----+-----+-----+----------------+-------+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = false)\n",
      " |-- Sex: string (nullable = false)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = false)\n",
      " |-- Fare: double (nullable = false)\n",
      " |-- Cabin: string (nullable = false)\n",
      " |-- Embarked: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_dataframe(df):\n",
    "\t# Drop columns with >80% missing values\n",
    "\ttotal_count = df.count()\n",
    "\tcolumns_to_drop = [col for col in df.columns if df.filter(F.col(col).isNull()).count() / total_count > 0.8]\n",
    "\tdf = df.drop(*columns_to_drop)\n",
    "\t\n",
    "\t# Replace missing values\n",
    "\tfor coluna in df.schema:\n",
    "\t\tcol_name = coluna.name\n",
    "\t\tdata_type = coluna.dataType\n",
    "\t\t\n",
    "\t\tif isinstance(data_type, DoubleType) or isinstance(data_type, IntegerType):\n",
    "\t\t\tmean_value = df.select(F.mean(F.col(col_name))).collect()[0][0]\n",
    "\t\t\tdf = df.fillna({col_name: mean_value})\n",
    "\t\telif isinstance(data_type, StringType):\n",
    "\t\t\tdf = df.fillna({col_name: \"Desconhecido\"})\n",
    "\t\n",
    "\t# Drop columns with variance equals to 0\n",
    "\tnumeric_columns = [col for col, dtype in df.dtypes if isinstance(dtype, NumericType)]\n",
    "\tvariances = df.select([F.variance(F.col(col)).alias(col) for col in numeric_columns]).collect()[0].asDict()\n",
    "\tcolumns_to_drop = [col for col, var in variances.items() if var == 0]\n",
    "\tdf = df.drop(*columns_to_drop)\n",
    "\t\n",
    "\treturn df\n",
    "\n",
    "# Apply the function to the dataframe\n",
    "abt_01 = preprocess_dataframe(abt_00)\n",
    "abt_01.show(5)\n",
    "abt_01.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento de variáveis numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de seleção de variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corte por IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + IV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
